{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46058a12-5759-4ac1-b48c-2e14f17cb6a1",
   "metadata": {},
   "source": [
    "# Robust Lookup Table: AI Model\n",
    "\n",
    "The goal of this notebook is to explore and experiment with a deep learning approach to create the Robust Lookup Table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7841dab-03b0-4b03-9479-5cccc304e109",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "* #### I. Generate fake scenarios & backends\n",
    "* #### II. Design Deep learning model\n",
    "* #### II. Train model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e3dbf-1d1e-4d59-88ec-4169d3974030",
   "metadata": {},
   "source": [
    "## I. Generate fake scenarios & backends\n",
    "\n",
    "### I.1. Generate fake Scenarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443cc807-dd0b-463a-b89a-48e79f304667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import uuid\n",
    "import hashlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8e62dcb5-b21d-4151-9f85-08e446c60e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Fake scenarios\n",
    "\n",
    "# ScenarioGeneratorConfig\n",
    "# - size: the fixed size of the lookup table.\n",
    "# - nBeforeBounds(x, y): nBefore ∈ [x, y].\n",
    "# - nAfterBounds(x, y): nAfter ∈ [x, y].\n",
    "# - variance(x, y): x < min(nBefore,nAfter)/max(nBefore,nAfter); y < max(nBefore,nAfter) - min(nBefore,nAfter)\n",
    "# # - sizeBounds(x, y): lookup table size ∈ [x, y].\n",
    "class ScenarioGeneratorConfig:\n",
    "    size: int\n",
    "    nBeforeBounds: (int, int)\n",
    "    nAfterBounds: (int, int)\n",
    "    variance: (float, int)\n",
    "    # sizeBounds: (int, int)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        size: int,\n",
    "        nBeforeBounds: (int, int),\n",
    "        nAfterBounds: (int, int),\n",
    "        variance: (float, int),\n",
    "        # sizeBounds: (int, int),\n",
    "    ):\n",
    "        if nBeforeBounds[1] > size or nAfterBounds[1] > size:\n",
    "            raise Exception(\"nBeforeBounds and nAfterBounds cannot exceed size\")\n",
    "\n",
    "        self.size = size\n",
    "        self.nBeforeBounds = nBeforeBounds\n",
    "        self.nAfterBounds = nAfterBounds\n",
    "        self.variance = variance\n",
    "        # self.sizeBounds = sizeBounds\n",
    "\n",
    "class Scenario:\n",
    "    nBefore: int\n",
    "    nAfter: int\n",
    "    size: int\n",
    "\n",
    "def validate_scenario(cfg: ScenarioGeneratorConfig, scenario: Scenario) -> bool:\n",
    "    var = cfg.variance[0]\n",
    "    delta = cfg.variance[1]\n",
    "\n",
    "    _min = min([scenario.nBefore, scenario.nAfter])\n",
    "    _max = max([scenario.nBefore, scenario.nAfter])\n",
    "    _var = _min/_max\n",
    "    _delta = _max - _min\n",
    "    _sz = scenario.size\n",
    "\n",
    "    return _var <= var and _delta <= delta and _max <= _sz and _min != _max\n",
    "\n",
    "# creates a new scenario generator.\n",
    "def new_scenario_generator(cfg):\n",
    "    while True:\n",
    "        scenario = Scenario()\n",
    "        scenario.nBefore = random.randint(cfg.nBeforeBounds[0], cfg.nBeforeBounds[1])\n",
    "        scenario.nAfter = random.randint(cfg.nAfterBounds[0], cfg.nAfterBounds[1])\n",
    "        scenario.size = cfg.size\n",
    "        # scenario.size = random.randint(cfg.sizeBounds[0], cfg.sizeBounds[1])\n",
    "\n",
    "        if validate_scenario(cfg, scenario):\n",
    "            yield scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fcf07810-4c52-4fba-9ca5-a2d7c9385e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nBefore': 40, 'nAfter': 41, 'size': 47}\n",
      "{'nBefore': 29, 'nAfter': 37, 'size': 47}\n",
      "{'nBefore': 29, 'nAfter': 39, 'size': 47}\n"
     ]
    }
   ],
   "source": [
    "nBeforeBounds = (3, 47)\n",
    "nAfterBounds = (1, 47)\n",
    "variance = (1.0, 10)\n",
    "size = 47\n",
    "\n",
    "cfg = ScenarioGeneratorConfig(size, nBeforeBounds, nAfterBounds, variance)\n",
    "sc = new_scenario_generator(cfg)\n",
    "\n",
    "for i in range(3):\n",
    "    s = next(sc)\n",
    "    print(s.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf4bd8-2cc7-453e-b1cc-fab7a8378a3f",
   "metadata": {},
   "source": [
    "### I.2. Generate fake Backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "32047df2-0866-4136-9e1f-430147244ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_backend returns a dict representing a backend\n",
    "# k,v:\n",
    "# - id,uuid\n",
    "# - hash,int\n",
    "def new_backend():\n",
    "    id = uuid.uuid4()\n",
    "    _h = hashlib.sha256()\n",
    "    _h.update(id.bytes_le)\n",
    "    _b = _h.digest()\n",
    "    h = int.from_bytes(_b[24:32], \"little\")\n",
    "    \n",
    "    return (id, h)\n",
    "\n",
    "def new_backend_list_permutation(l: list, size: int) -> list:\n",
    "    _p = np.random.permutation(l)\n",
    "    return _p[0:size]\n",
    "\n",
    "# new_backend_generator takes a list of Scenario and yields a tuple of 2 lists of Backend.\n",
    "# The \"before\" list and the \"after\" list.\n",
    "def new_backend_generator(scenarioGenerator):\n",
    "    while True:\n",
    "        sc = next(scenarioGenerator)\n",
    "        _min = min([sc.nBefore, sc.nAfter])\n",
    "        _max = max([sc.nBefore, sc.nAfter])\n",
    "        isMinBefore = sc.nBefore < sc.nAfter\n",
    "        l_min = []\n",
    "        l_max = []\n",
    "\n",
    "        # create the l_max backend array.\n",
    "        for i in range(_max):\n",
    "            b = new_backend()\n",
    "            l_max.append(b)\n",
    "            if len(l_min) < _min:\n",
    "                l_min.append(b)\n",
    "\n",
    "        # create l_min array by randomly choosing _min elements of l_max.\n",
    "        l_min = new_backend_list_permutation(l_max, _min)\n",
    "\n",
    "        # sort both arrays.\n",
    "        l_max = sorted(l_max, key=lambda x: str(x[0]))\n",
    "        l_min = sorted(l_min, key=lambda x: str(x[0]))\n",
    "        \n",
    "        if isMinBefore:\n",
    "            yield (l_min, l_max)\n",
    "        else:\n",
    "            # print([x.__dict__ for x in l_min])\n",
    "            yield (l_max, l_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "68c41565-e10a-493d-b945-6a186cd70170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Before: len=25 example_value=[UUID('087b90d2-0195-47f7-9373-26f03bf00be4') 11470088727391372139]\n",
      "- After: len=35 example_value=(UUID('008f5c09-a190-4506-a9af-beb169a7de4e'), 13543712438097616289)\n",
      "- Before: len=39 example_value=(UUID('04bd519f-f052-40ff-83b6-3739ea0ef491'), 16152123668707616722)\n",
      "- After: len=30 example_value=[UUID('04bd519f-f052-40ff-83b6-3739ea0ef491') 16152123668707616722]\n"
     ]
    }
   ],
   "source": [
    "generator = new_backend_generator(new_scenario_generator(cfg))\n",
    "\n",
    "for i in range(2):\n",
    "    t = next(generator)\n",
    "    print(f\"- Before: len={len(t[0])} example_value={t[0][0]}\")\n",
    "    print(f\"- After: len={len(t[1])} example_value={t[1][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc854e-b33e-4187-bd5e-334954c70238",
   "metadata": {},
   "source": [
    "## II. Design Deep learning model\n",
    "\n",
    "### Definitions\n",
    "\n",
    "- Let `m` equal to the length of the lookup table: `m=len(lookup_table)`.\n",
    "- Let `input` an array of length equal to m: `len(input)=m`. \n",
    "  - Each entry in `input` represents a backend.\n",
    "- Let `h(i)` the hash of the i-th backend in `input`.\n",
    "- Let `input[i]=h(i) % m`.\n",
    "- Let `n` the number of backend actually represented in `input`.\n",
    "  - Because: `nAfter != nBefore` and `max(nAfter,nBefore) <= m`.\n",
    "- Let `output` a matrix of size `m*m`.\n",
    "- Let `output[j]` the j-th row in the `output` matrix.\n",
    "  - The j-th row of the `output` matrix represents the j-th entry of\n",
    "     the lookup table.\n",
    "- Let `o(i,j)` the i-th entry in `output[j]`.\n",
    "  - `o(i,j)` is the probability of the i-th backend being mapped to the\n",
    "     j-th entry of the lookup table.\n",
    "\n",
    "### Input data\n",
    "\n",
    "Problem 1: How to represent data in the inputs that is unmapped? \n",
    "- E.g. if the modulo of a hash is equal to 0, how should we represent entries\n",
    "  that are out of bound.\n",
    "- In other words, if `n=13` and `m=47`, how do we represent the entries with\n",
    "  index in the range of [13:47]?\n",
    "\n",
    "Definitions:\n",
    "- Let `in-bound` entries the name of entries in the range [0:13].\n",
    "- Let `out-of-bound` entries the name of entries in the range [13:47].\n",
    "\n",
    "Solution:\n",
    "- If we normalize `in-bound` entries as real numbers in [0,1], then we can\n",
    "set `out-of-bound` entries to `-1`.\n",
    "- Another solution would be to represent the input as a `m*m` matrix. \n",
    "  - The i-th row representing the i-th backend.\n",
    "  - The j-th entry in i-th row representing the modulo of the hash of the i-th backend\n",
    "  - If the j-th entry of the i-th row is equal to 1, it means \n",
    "  - If all entries of the i-th row are equal to 0, then it means there are no backends \n",
    "    there.\n",
    "\n",
    "Problem 2: what if multiple backend have the same modulo?\n",
    "- This is particularly problematic if 2 subsequent backends resolves to the same modulo\n",
    "  and 1 of the backend becomes down. \n",
    "- In that case, there is not way to identify which backend was dropped from the model's\n",
    "  point of view. \n",
    "- Hence there is a 50% chance to reaffect packets away from a healthy backend.\n",
    "\n",
    "Solution:\n",
    "- Compute multiple hash for each backend. Or split the 128-bit hash into 4 int32 and \n",
    "  compute 4 modulo. The probability of encountering 4 collisions in the same order\n",
    "  would be significantly lower (the actual improvement has not be calculated).\n",
    "\n",
    "### Model training:\n",
    "\n",
    "- Pass the \"before\" training data through the model.\n",
    "- Pass the \"after\" training data through the model.\n",
    "- Compute \"even distribution\" score: to ensure the backends are evenly\n",
    "  distributed in the output.\n",
    "- Compute \"validity\" score: \n",
    "  - to ensure the model does not make inference `out-of-bound`.\n",
    "- Optional: compute a \"confidence score\", by calculating how likely the top inference\n",
    "  is compared to other o(i,j) value in i-th row.\n",
    "- Compute the % of unchanged entries between \"Before\" and \"After\".\n",
    "- Compute the stability score.\n",
    "- Compute loss function from \"validity\", \"even distribution\" and \"stability\" score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cf8f3622-b56c-46b8-9272-aaf632881753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "037a9eff-8568-41cc-aa23-7894c306e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN takes `m` (int) as a paremeter. \n",
    "# `m` is the length of the lookup table.\n",
    "# input dimensions is a tensor of size `m` and dimension 1.\n",
    "# output dimensions are `m*m` matrices.\n",
    "class NN(nn.Module):\n",
    "    size: int\n",
    "\n",
    "    def __init__(self, m: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.size = m\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(m, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, m*m),\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> (list, list):\n",
    "        _bef_in, _aft_in = x\n",
    "\n",
    "        # -- prepare\n",
    "        bef_in = self.clean_input(_bef_in)\n",
    "        aft_in = self.clean_input(_aft_in)\n",
    "\n",
    "        # -- infer\n",
    "        _bef_out = self.forward_once(bef_in)\n",
    "        _bef_aft = self.forward_once(aft_in)\n",
    "\n",
    "        # -- post-process\n",
    "        bef_out = self.clean_output(_bef_in, _bef_out)\n",
    "        aft_out = self.clean_output(_aft_in, _aft_out)\n",
    "        \n",
    "        return bef_out, aft_out\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        # -- debug\n",
    "        print(\"x:\", x)\n",
    "        # x = self.flatten(x)\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "    def clean_input(self, x):\n",
    "        out = torch.full((size,), -1)\n",
    "        for i, backend in enumerate(x):\n",
    "            # backend[1] is the hash.\n",
    "            out[i] = backend[1] % self.size\n",
    "        return out\n",
    "\n",
    "    def clean_output(self, x_in, x_out):\n",
    "        # We want to return a list of length `m` that\n",
    "        # associate each i-th entry with a backend uuid.\n",
    "        # \n",
    "        # An entry at index `i` is obtained by fetching the\n",
    "        # uuid of the backend at index `j` of `x_in`.\n",
    "        # `j` is the index of the highest value of the j-th\n",
    "        # row of `x_out`.\n",
    "        # \n",
    "        # - x_in is the raw input.\n",
    "        # - x_out are matrices of size m*m.\n",
    "        out = []\n",
    "        for row in x_out:\n",
    "            # the first element is the max value.\n",
    "            # we may want to output it in order to calculate the loss.\n",
    "            # this would measure the confidence of the algorithm in the inference. \n",
    "            _, j = torch.max(row, 0) \n",
    "            out.append(str(x_in[j][0]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "76a0b770-0e62-454b-824a-b066ec59d855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8188, 0.7926, 0.7015, 0.2051, 0.6772])\n",
      "tensor(0)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([47])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5)\n",
    "y = [ 0, 1, 2, 3, 4 ]\n",
    "print(x)\n",
    "print(torch.max(x, 0)[1])\n",
    "print(y[torch.max(x, 0)[1]])\n",
    "\n",
    "out = torch.full((size,), -1)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9ee65203-9bf5-4bd3-9162-fc1ed8496699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([ 2, 29, 21, 23, 39, 11, 17,  7, 16, 41, 25, 10, 18, 22,  4, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Long and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m NN(\u001b[38;5;241m47\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[162], line 29\u001b[0m, in \u001b[0;36mNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m aft_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_input(_aft_in)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# -- infer\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m _bef_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbef_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m _bef_aft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_once(aft_in)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# -- post-process\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[162], line 42\u001b[0m, in \u001b[0;36mNN.forward_once\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# x = self.flatten(x)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_relu_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Long and Float"
     ]
    }
   ],
   "source": [
    "model = NN(47).to(device)\n",
    "print(model(next(generator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5e8cb98-e897-4657-8f15-99aa8302cad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m         loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(weight \u001b[38;5;241m*\u001b[39m (output \u001b[38;5;241m-\u001b[39m target)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m---> 13\u001b[0m \u001b[43mLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 9\u001b[0m, in \u001b[0;36mLoss.forward\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m      7\u001b[0m before, after \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(before, after)\n\u001b[0;32m----> 9\u001b[0m weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(\u001b[43mtarget\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameter\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(weight \u001b[38;5;241m*\u001b[39m (output \u001b[38;5;241m-\u001b[39m target)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "        # self.parameter = nn.Parameter(torch.tensor(some_parameter)) # Example learnable parameter\n",
    "\n",
    "    def forward(self, inputs, outputs):\n",
    "        before, after = inputs\n",
    "        weight = torch.abs(target) + self.parameter\n",
    "        loss = torch.mean(weight * (output - target)**2)\n",
    "        return loss\n",
    "\n",
    "Loss().forward((0, 1), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f4ae4-3889-4063-a819-baf7b4b9efb2",
   "metadata": {},
   "source": [
    "## III. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60aed8f5-f55e-45a2-8ff6-97bbd763a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm parameters\n",
    "m = 47\n",
    "nBeforeBounds = (3, m)\n",
    "nAfterBounds = (1, m)\n",
    "variance = (1.0, 10)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ea76835-e163-478f-bedc-32eb49a270fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(backend_generator)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# -- run model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# -- compute loss\u001b[39;00m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(inputs, outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[44], line 17\u001b[0m, in \u001b[0;36mNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_relu_stack(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/flatten.py:53\u001b[0m, in \u001b[0;36mFlatten.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_dim)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "cfg = ScenarioGeneratorConfig(m, nBeforeBounds, nAfterBounds, variance)\n",
    "backend_generator = new_backend_generator(new_scenario_generator(cfg))\n",
    "\n",
    "model = NN(m).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = Loss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(batch_size):\n",
    "        # -- reset optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # -- generate inputs\n",
    "        inputs = next(backend_generator)\n",
    "\n",
    "        # -- run model\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # -- compute loss\n",
    "        loss = loss_fn(inputs, outputs)\n",
    "\n",
    "        #        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e803b-1074-4260-89c2-d8180413d15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
